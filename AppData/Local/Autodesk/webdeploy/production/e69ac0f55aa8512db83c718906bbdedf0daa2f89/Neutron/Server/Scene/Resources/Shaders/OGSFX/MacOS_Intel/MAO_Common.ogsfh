//**************************************************************************/
// Copyright (c) 2008 Autodesk, Inc.
// All rights reserved.
//
// These coded instructions, statements, and computer programs contain
// unpublished proprietary information written by Autodesk, Inc., and are
// protected by Federal copyright law. They may not be disclosed to third
// parties or copied or duplicated in any form, in whole or in part, without
// the prior written consent of Autodesk, Inc.
//**************************************************************************/
// DESCRIPTION: Screen space ambient occlusion - common definitions.
// AUTHOR: Mauricio Vives, converted to OGSFX by Eric Haines, July 2013
// CREATED: October 2008
//**************************************************************************/

#ifndef _MAO_Common_FXH_
#define _MAO_Common_FXH_

// The offset of the current tile, relative to the full image.  This is (0.0, 0.0) when not tiling.
uniform vec2 gTileOffset : TileOffset;

// The scale of the current tile, relative to the full image.  This is (1.0, 1.0) when not tiling.
uniform vec2 gTileScale : TileScale;

// Screen size, in pixels.
uniform vec2 gScreenSize : ViewportPixelSize ;


// World transformation.
uniform mat4 gWXf : World;

// World-view-projection transformation.
uniform mat4 gWVPXf : WorldViewProjection;

// World-view transformation.
uniform mat4 gWVXf : WorldView;

// World-view transformation, inverse transpose.
uniform mat4 gWVITXf : WorldViewInverseTranspose;

// Projection transformation and view scale, i.e. view-space size at a distance of one.
// NOTE: This need to be the projection transformation of the scene, not the screen quad used for
// post-processing.  In general, the SSAO effect is split into multiple independent passes, so the
// "Projection" semantic is not appropriate and the value must be set manually.  For FX Composer,
// the SSAO effect is a set of *related* passes in a central technique using SAS scripting, which
// include the scene passes, so the "Projection" semantic can be used.
// NOTE: The matrix elements used here could be negative, e.g. in a right-handed coordinate system,
// and the shaders that use this depend on it to support the proper coordinate system.
uniform mat4 gProjection;

// Whether a perspective view is being used.
uniform bool gPerspectiveFlag = false;

// The radius of the SSAO samples, as a fracttion of the screen width.
uniform float gSampleRadius = 0.1;

////////////////////////////////////////////////////////////////////////////////////////////////////
// Screen Quad Vertex Shader
////////////////////////////////////////////////////////////////////////////////////////////////////

// Vertex shader input structure.
attribute VS_INPUT_ScreenQuad
{
    vec3 Pos : POSITION;
    vec2 UV : TEXCOORD0;
}

// Vertex shader output structure.
attribute VS_TO_PS_ScreenQuad
{
    vec2 VSUV : TEXCOORD0;
    vec2 VSUVTile : TEXCOORD1;
}

attribute pixelOut {
    vec4 colorOut:COLOR0;
}

// Vertex shader.
// VS_TO_PS_ScreenQuad VS_ScreenQuad(VS_INPUT_ScreenQuad In)
GLSLShader VS_ScreenQuad
{
    void main()
    {
        // If the origin is the bottom, adjust the tile offset to be relative to the bottom (instead of
        // the top, which it normally is.
        vec2 localTileOffset = gTileOffset;
        #ifdef UV_ORIGIN_BOTTOM
        // note: GLSL does not allow reassignment of uniform values, so we need a local here
        localTileOffset.y = 1.0 - gTileOffset.y - gTileScale.y;
        #endif

        // Output the position in clip space, and the texture coordinates modified by the tile offset
        // the scale.  The "UV" texture coordinates are thus relative to the *full* image, not the tile.
        // Also output the unmodified texture coordinates as "UVTile" (the tile texture coordinates).
        gl_Position = gWVPXf*vec4(Pos, 1.0);
        VSUV = (UV * gTileScale) + localTileOffset;
        VSUVTile = UV;
    }
}

// Whether the projection matrix flips Z: -1.0 if so, otherwise 1.0.
uniform float gProjZSense : ProjectionZSense ;

GLSLShader SpaceConvert
{
    // Get depth value in camera view space
    float Depth3D(float d)
	{
#ifdef NDCDEPTH
        // If depth in NDC(normalized device coordinate), converse depth from screen space to camera
		// view space.

        // If d is more than or equal to 1.0, it is background, return 0.
        float diff = 1.0 - d;
        if (diff < 1e-10)
            return 0.0;

        // Inverse projection to get depth in camera view space
        // For projection, we have (x,y,z,w)proj = (x,y,z,1)camera * ProjMatrix. Fetch the z related
        // equations (ProjMatrix[i][j] means matrix element at ith row jth column):
        //      ProjMatrix[2][0] * Xcamera + ProjMatrix[2][1] * Ycamera + ProjMatrix[2][2] * Zcamera + ProjMatrix[2][3] = Zproj
        //      ProjMatrix[3][0] * Xcamera + ProjMatrix[3][1] * Ycamera + ProjMatrix[3][2] * Zcamera + ProjMatrix[3][3] = Wproj
        //    As ProjMatrix[2][0] == ProjMatrix[2][1] == ProjMatrix[3][0] == ProjMatrix[3][1] == 0 for projection matrix,
        //      and Zproj/Wproj is the input d (depth in NDC)
        //    so dividing these two equations, we get,
        //      (ProjMatrix[2][2] * Zcamera + ProjMatrix[2][3]) / (ProjMatrix[3][2] * Zcamera + ProjMatrix[3][3]) = d
        //    Resolve Zcamera as,
        //      Zcamera = (ProjMatrix[3][3] * d - ProjMatrix[2][3]) / (ProjMatrix[2][2] - ProjMatrix[3][2] * d)
        // Note, OGS matrix is row major, ProjMatrix[2][3] = gProjection[3][2], ProjMatrix[3][2] = gProjection[2][3]

        return gProjZSense*((gProjection[3][3]*d - gProjection[3][2])
			               /(gProjection[2][2]-gProjection[2][3]*d));
#else
        // else, depth is already in camera view space, return directly
        return d;
#endif
	}
}

GLSLShader Utilities
{
    // View-space size at a distance of one.
    vec2 ViewScale()
    {
        return  1.0 / vec2(gProjection[0][0], gProjection[1][1]);
    }

    // Compute the depth scale from the depth of the current pixel and the view scale.  This
    // is the vector from the center of the screen to the corners of the screen in view space,
    // at the current depth.
    vec2 DepthScale(float depth, vec2 viewScale)
    {
        vec2 depthScale = (gPerspectiveFlag ? depth : 1.0) * viewScale;
	    return depthScale;
    }

    // Reconstruct the view-space (3D) position of the pixel from the depth. Input uv coordinate value
    // of pixel on screen and the depth value in view space. Return the 3D position in view space.
    vec3 Reconstruct3DPosition(vec2 texUV, float depth, vec2 depthScale)
    {
        // Reconstruct the view-space (3D) position of the current pixel from the depth, the depth
        // scale, and the normalized [0.0, 1.0] screen position.
        vec2 pos2D = texUV * vec2(2.0, 2.0) - vec2(1.0, 1.0);
        vec3 pos3D = vec3(pos2D * depthScale, depth);
        return pos3D;
    }
}
#endif //_MAO_Common_FXH
